{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7395e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 常用评估器\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 自定义评估器支持模块\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b217786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Using cached hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: six in /Users/pro/opt/anaconda3/envs/ML/lib/python3.7/site-packages (from hyperopt) (1.16.0)\n",
      "Collecting py4j\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Collecting networkx>=2.2\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cloudpickle\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/pro/opt/anaconda3/envs/ML/lib/python3.7/site-packages (from hyperopt) (1.21.6)\n",
      "Requirement already satisfied: scipy in /Users/pro/opt/anaconda3/envs/ML/lib/python3.7/site-packages (from hyperopt) (1.7.3)\n",
      "Collecting future\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=2bd610c4cbb559dfd3b98c60bb657987213ba05c1190a7183c813928a4431bbb\n",
      "  Stored in directory: /Users/pro/Library/Caches/pip/wheels/52/2a/fc/520209cfa6448febd490720a0b09036cb367628f7c4e9cc172\n",
      "Successfully built future\n",
      "Installing collected packages: py4j, tqdm, networkx, future, cloudpickle, hyperopt\n",
      "Successfully installed cloudpickle-2.2.1 future-0.18.3 hyperopt-0.2.7 networkx-2.6.3 py4j-0.10.9.7 tqdm-4.65.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3461ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcc = pd.read_csv('/Users/pro/Desktop/【特征工程】电信用户流失案例/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "category_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "                'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
    "                'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "                'PaymentMethod']\n",
    "\n",
    "# 连续字段\n",
    "numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    " \n",
    "# 标签\n",
    "target = 'Churn'\n",
    "\n",
    "# ID列\n",
    "ID_col = 'customerID'\n",
    "\n",
    "# 验证是否划分能完全\n",
    "assert len(category_cols) + len(numeric_cols) + 2 == tcc.shape[1]\n",
    "\n",
    "# 连续字段转化\n",
    "tcc['TotalCharges']= tcc['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n",
    "tcc['MonthlyCharges'] = tcc['MonthlyCharges'].astype(float)\n",
    "\n",
    "# 缺失值填补\n",
    "tcc['TotalCharges'] = tcc['TotalCharges'].fillna(0)\n",
    "\n",
    "# 标签值手动转化 \n",
    "tcc['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "tcc['Churn'].replace(to_replace='No',  value=0, inplace=True)\n",
    "features = tcc.drop(columns=[ID_col, target]).copy()\n",
    "labels = tcc['Churn'].copy()\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train, test = train_test_split(tcc, random_state=22)\n",
    "\n",
    "X_train = train.drop(columns=[ID_col, target]).copy()\n",
    "X_test = test.drop(columns=[ID_col, target]).copy()\n",
    "\n",
    "y_train = train['Churn'].copy()\n",
    "y_test = test['Churn'].copy()\n",
    "\n",
    "X_train_seq = pd.DataFrame()\n",
    "X_test_seq = pd.DataFrame()\n",
    "\n",
    "# 年份衍生\n",
    "X_train_seq['tenure_year'] = ((72 - X_train['tenure']) // 12) + 2014\n",
    "X_test_seq['tenure_year'] = ((72 - X_test['tenure']) // 12) + 2014\n",
    "\n",
    "# 月份衍生\n",
    "X_train_seq['tenure_month'] = (72 - X_train['tenure']) % 12 + 1\n",
    "X_test_seq['tenure_month'] = (72 - X_test['tenure']) % 12 + 1\n",
    "\n",
    "# 季度衍生\n",
    "X_train_seq['tenure_quarter'] = ((X_train_seq['tenure_month']-1) // 3) + 1\n",
    "X_test_seq['tenure_quarter'] = ((X_test_seq['tenure_month']-1) // 3) + 1\n",
    "\n",
    "# 独热编码\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_train_seq)\n",
    "\n",
    "seq_new = list(X_train_seq.columns)\n",
    "\n",
    "\n",
    "def cate_colName(Transformer, category_cols, drop='if_binary'):\n",
    "    \"\"\"\n",
    "    离散字段独热编码后字段名创建函数\n",
    "    \n",
    "    :param Transformer: 独热编码转化器\n",
    "    :param category_cols: 输入转化器的离散变量\n",
    "    :param drop: 独热编码转化器的drop参数\n",
    "    \"\"\"\n",
    "    \n",
    "    cate_cols_new = []\n",
    "    col_value = Transformer.categories_\n",
    "    \n",
    "    for i, j in enumerate(category_cols):\n",
    "        if (drop == 'if_binary') & (len(col_value[i]) == 2):\n",
    "            cate_cols_new.append(j)\n",
    "        else:\n",
    "            for f in col_value[i]:\n",
    "                feature_name = str(j) + '_' + str(f)\n",
    "                cate_cols_new.append(feature_name)\n",
    "    return(cate_cols_new)\n",
    "\n",
    "\n",
    "# 创建带有列名称的独热编码之后的df\n",
    "X_train_seq = pd.DataFrame(enc.transform(X_train_seq).toarray(), \n",
    "                           columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "X_test_seq = pd.DataFrame(enc.transform(X_test_seq).toarray(), \n",
    "                          columns = cate_colName(enc, seq_new, drop=None))\n",
    "\n",
    "# 调整index\n",
    "X_train_seq.index = X_train.index\n",
    "X_test_seq.index = X_test.index\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit(X_train[category_cols])\n",
    "\n",
    "X_train_OE = pd.DataFrame(ord_enc.transform(X_train[category_cols]), columns=category_cols)\n",
    "X_train_OE.index = X_train.index\n",
    "X_train_OE = pd.concat([X_train_OE, X_train[numeric_cols]], axis=1)\n",
    "\n",
    "X_test_OE = pd.DataFrame(ord_enc.transform(X_test[category_cols]), columns=category_cols)\n",
    "X_test_OE.index = X_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, X_test[numeric_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7bb80f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class logit_threshold(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, penalty='l2', C=1.0, max_iter=1e8, solver='lbfgs', l1_ratio=None, class_weight=None, thr=0.5):\n",
    "        self.penalty = penalty\n",
    "        self.C = C\n",
    "        self.max_iter = max_iter\n",
    "        self.solver = solver\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.thr = thr\n",
    "        self.class_weight = class_weight\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        clf = LogisticRegression(penalty = self.penalty, \n",
    "                                 C = self.C, \n",
    "                                 solver = self.solver, \n",
    "                                 l1_ratio = self.l1_ratio,\n",
    "                                 class_weight=self.class_weight, \n",
    "                                 max_iter=self.max_iter, \n",
    "                                 random_state=12)\n",
    "        clf.fit(X, y)\n",
    "        self.coef_ = clf.coef_\n",
    "        self.clf = clf\n",
    "        return self\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        res_proba = self.clf.predict_proba(X)\n",
    "        return res_proba\n",
    "    \n",
    "    def predict(self, X):\n",
    "        res = (self.clf.predict_proba(X)[:, 1]>=self.thr) * 1\n",
    "        return res\n",
    "\n",
    "    \n",
    "logistic_search = load('logistic_search.joblib')\n",
    "tree_model = load('tree_model.joblib')\n",
    "RF_0 = load('RF_0.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc36ba",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f63046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集上的预测结果\n",
    "train_prediction1 = logistic_search.best_estimator_.predict(X_train_OE)\n",
    "train_prediction2 = tree_model.predict(X_train_OE)\n",
    "train_prediction3 = RF_0.predict(X_train_OE)\n",
    "\n",
    "# 训练集上的预测概率(预测为1的概率)\n",
    "train_prediction1_proba = logistic_search.best_estimator_.predict_proba(X_train_OE)[:, 1]\n",
    "train_prediction2_proba = tree_model.predict_proba(X_train_OE)[:, 1]\n",
    "train_prediction3_proba = RF_0.predict_proba(X_train_OE)[:, 1]\n",
    "\n",
    "# 测试集上的预测结果\n",
    "test_prediction1 = logistic_search.best_estimator_.predict(X_test_OE)\n",
    "test_prediction2 = tree_model.predict(X_test_OE)\n",
    "test_prediction3 = RF_0.predict(X_test_OE)\n",
    "\n",
    "# 测试集上的预测概率\n",
    "test_prediction1_proba = logistic_search.best_estimator_.predict_proba(X_test_OE)[:, 1]\n",
    "test_prediction2_proba = tree_model.predict_proba(X_test_OE)[:, 1]\n",
    "test_prediction3_proba = RF_0.predict_proba(X_test_OE)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21d56b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99327033, 0.00672967],\n",
       "       [0.48125643, 0.51874357],\n",
       "       [0.89506715, 0.10493285],\n",
       "       ...,\n",
       "       [0.39270528, 0.60729472],\n",
       "       [0.9843395 , 0.0156605 ],\n",
       "       [0.99464364, 0.00535636]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_0.predict_proba(X_train_OE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "979bac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f8d604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('lr', logistic_search.best_estimator_), \n",
    "              ('tree', tree_model), \n",
    "              ('rf', RF_0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb83a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VC_hard = VotingClassifier(estimators).fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38f00c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8345323741007195, 0.7910278250993753)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC_hard.score(X_train_OE, y_train), VC_hard.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44beb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "VC_soft = VotingClassifier(estimators, voting='soft').fit(X_train_OE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a62d9716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8258235516849678, 0.787052810902896)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VC_soft.score(X_train_OE, y_train), VC_soft.score(X_test_OE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292add84",
   "metadata": {},
   "source": [
    "## Advance Voting & Advance Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9369a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "Voting_train_GN = (np.power(train_prediction1_proba * \n",
    "                            train_prediction2_proba * \n",
    "                            train_prediction3_proba, 1/3) >= 0.5) * 1\n",
    "\n",
    "Voting_test_GN = (np.power(test_prediction1_proba * \n",
    "                           test_prediction2_proba * \n",
    "                           test_prediction3_proba, 1/3) >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "676b0f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8237410071942446, 0.7842135150482681)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Voting_train_GN, y_train), accuracy_score(Voting_test_GN, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5dc1f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.48:\n",
      "train_Accuracy 0.8263915184\n",
      "test_Accuracy 0.7904599659\n",
      "threshold 0.50:\n",
      "train_Accuracy 0.8258235517\n",
      "test_Accuracy 0.7870528109\n",
      "threshold 0.52:\n",
      "train_Accuracy 0.8226050738\n",
      "test_Accuracy 0.7813742192\n"
     ]
    }
   ],
   "source": [
    "for thr in [0.48, 0.5, 0.52]:\n",
    "\n",
    "    Voting_train_soft_thr = (((train_prediction1_proba + \n",
    "                               train_prediction2_proba + \n",
    "                               train_prediction3_proba) / 3) >= thr) * 1\n",
    "    \n",
    "    train_acc = accuracy_score(Voting_train_soft_thr, y_train)\n",
    "    \n",
    "    Voting_test_soft_thr = (((test_prediction1_proba + \n",
    "                              test_prediction2_proba + \n",
    "                              test_prediction3_proba) / 3) >= thr) * 1\n",
    "    \n",
    "    test_acc = accuracy_score(Voting_test_soft_thr, y_test)\n",
    "    \n",
    "    print(\"threshold %0.2f:\" % thr)\n",
    "    print(\"train_Accuracy %0.10f\" % train_acc)\n",
    "    print(\"test_Accuracy %0.10f\" % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95d0ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b7b20b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_space = {'thr': hp.uniform(\"thr\",0.4,0.6)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2137e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义目标函数\n",
    "def hyperopt_objective(params):\n",
    "    thr = params['thr']\n",
    "    \n",
    "    Voting_train_soft_thr = (((train_prediction1_proba + \n",
    "                               train_prediction2_proba + \n",
    "                               train_prediction3_proba) / 3) >= thr) * 1\n",
    "    \n",
    "    train_acc = accuracy_score(Voting_train_soft_thr, y_train)\n",
    "    \n",
    "    return -train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2742f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_hyperopt(max_evals):\n",
    "    params_best = fmin(hyperopt_objective,\n",
    "                       space=params_space,\n",
    "                       algo=tpe.suggest,\n",
    "                       max_evals=max_evals, \n",
    "                       rstate=np.random.default_rng(17))    \n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e30997a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███| 3000/3000 [00:24<00:00, 124.33trial/s, best loss: -0.8271488072699735]\n"
     ]
    }
   ],
   "source": [
    "params_best = param_hyperopt(max_evals=3000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a766e77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4787137835346912"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_best['thr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b22d46c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7904599659284497"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Voting_test_soft_thr = (((test_prediction1_proba + \n",
    "                          test_prediction2_proba + \n",
    "                          test_prediction3_proba) / 3) >= params_best['thr']) * 1\n",
    "    \n",
    "test_acc = accuracy_score(Voting_test_soft_thr, y_test)\n",
    "\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71d3b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数空间\n",
    "params_space = {'thr': hp.uniform(\"thr\",0.4,0.6)}\n",
    "\n",
    "# 定义目标函数\n",
    "def hyperopt_objective_test(params):\n",
    "    thr = params['thr']\n",
    "    \n",
    "    Voting_test_soft_thr = (((test_prediction1_proba + \n",
    "                              test_prediction2_proba + \n",
    "                              test_prediction3_proba) / 3) >= thr) * 1\n",
    "\n",
    "    test_acc = accuracy_score(Voting_test_soft_thr, y_test)\n",
    "    \n",
    "    return -test_acc\n",
    "\n",
    "# 定义优化函数\n",
    "def param_hyperopt(max_evals):\n",
    "    params_best = fmin(hyperopt_objective_test,\n",
    "                       space=params_space,\n",
    "                       algo=tpe.suggest,\n",
    "                       max_evals=max_evals, \n",
    "                       rstate=np.random.default_rng(17))    \n",
    "    return params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66f454a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███| 3000/3000 [00:23<00:00, 127.22trial/s, best loss: -0.7915956842703009]\n"
     ]
    }
   ],
   "source": [
    "params_best = param_hyperopt(max_evals=3000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bf7c31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thr': 0.4714998631942625}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e5af68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8254449072321091"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集得分\n",
    "Voting_train_soft_thr = (((train_prediction1_proba + \n",
    "                           train_prediction2_proba + \n",
    "                           train_prediction3_proba) / 3) >= params_best['thr']) * 1\n",
    "    \n",
    "train_acc = accuracy_score(Voting_train_soft_thr, y_train)\n",
    "\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66ee4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e8444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
